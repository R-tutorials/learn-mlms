[["09-module-9.html", "Chapter 10 Multilevel Modelling with Repeated Measures Data 10.1 Learning Objectives 10.2 Data Demonstration 10.3 Conclusion", " Chapter 10 Multilevel Modelling with Repeated Measures Data 10.1 Learning Objectives In this chapter, we will review fitting MLMs for repeated measures data. The learning objectives for this chapter are: Review multilevel modelling concepts discussed so far; Recognize when data are repeated measures and in the correct format for multilevel modelling; Conduct multilevel modelling on repeated measures data; Interpret coefficients for repeated measures data. All materials for this chapter are available for download here. 10.2 Data Demonstration 10.2.1 Load Dependencies For this data demo, we will use the following packages: library(lme4) # for multilevel models library(lmerTest) # for p-values library(performance) # for ICC 10.2.2 Review of Multilevel Modelling Procedure Multilevel modelling in repeated measures data is a new application of the techniques weve covered so far, so lets briefly review the steps in our modelling framework so far: Establish solid theory and measurement, decide whether you need MLMs for your question Run random-intercept-only (i.e., null) model to calculate ICC and quantify extent of clustering in data Build model incrementally adding fixed and random effects per your theory, considering centering and estimation (REML or FIML) choices Conduct deviance test to compare model fits If you run into estimation issues, change your optimizer or remove problematic effects Report results: coefficients, significance, plausible values ranges, any changes made to address estimation issues 10.2.3 Multilevel Models for Repeated Measures Thus far, weve been using a cross-sectional example of students clustered within schools. Our level-1 variables have been about traits that students vary on (e.g., age, gender, SES) while our level-2 variables have been about traits that schools vary on (e.g., whether they are public or private schools). With repeated measures data, measures are clustered within person rather than having people clustered within some organizational structure. The level-1 variables are about traits that the measures vary on (e.g., experimental manipulations) while level-2 variables are about traits that people vary on (e.g., age, gender, SES). For example, imagine we show participants pictures of lines and ask them to estimate the line length. We measure how long it takes them to rate each line. A level-1 variable would be the line length; each participant sees several lines of different lengths. A level-2 variable would be something demographic like a participants age or gender; each person has the same value on the variable for the entire experiment. In this chapter, well look at repeated measures data without time in the model. In Chapter 10, well look at repeated measures data with time in the model, i.e., longitudinal models. 10.2.3.1 Data Structures: Long vs Wide Imagine you were measuring weight and caloric intake. If you have historically worked with repeated measures data in an ANOVA framework, you are probably used to working with data in a wide format, i.e., one row per participant with different variables for different measurement instances. id weight1 weight2 calories1 calories2 1 200 190 3500 3300 2 150 160 3200 3100 In MLMs, you need to use data in a long format where one row is one measurement occasion: id weight calories measurement_occasion 1 200 3500 1 1 190 3300 2 2 150 3200 1 2 160 3100 2 This requires transposing your data, which you can read more about here. An aside: you might also be used to thinking listwise deletion deletes an entire participant, because listwise deletion deletes rows with any missing data and in wide data one row is one participant. In long data, listwise deletion means deleting one measurement instance, not necessarily an entire participant. For example, if a participant answers a questionnaire a first time, then at one follow-up, but not at the second follow-up, listwise deletion will only remove their third row full of NAs; youll keep their data from the first two questionnaires. 10.2.4 Our Data: Reaction Time The data used in this module are used as an example in Hoffman and Rovine (2007). The article and supporting materials can be found here: http://www.lesahoffman.com/Research/MLM.html data &lt;- read.csv(&#39;hoffman2007.csv&#39;) Lets look at our data: head(data) ## X id sex age NAME rt_sec Item meaning salience lg_rt oldage yrs65 c_mean c_sal ## 1 1 1 1 20 rt_sec1 4.662 1 3.5 4.0 1.5394445 0 0 0.5 1.0 ## 2 2 1 1 20 rt_sec2 6.660 2 0.0 3.0 1.8961195 0 0 -3.0 0.0 ## 3 3 1 1 20 rt_sec3 6.602 3 4.0 2.0 1.8873726 0 0 1.0 -1.0 ## 4 4 1 1 20 rt_sec4 1.332 4 4.0 4.0 0.2866816 0 0 1.0 1.0 ## 5 5 1 1 20 rt_sec5 1.332 5 0.0 5.0 0.2866816 0 0 -3.0 2.0 ## 6 6 1 1 20 rt_sec7 1.302 7 3.5 4.5 0.2639015 0 0 0.5 1.5 For this data demo the outcome of interest is the log of reaction time for participants to detect a change during a picture viewing task (rt_sec). The pictures varied on two dimensions: how meaningful driving was to the picture (meaning) and how salient the change was in the picture (salient). For this analysis we will focus on the variables centered from the midpoint of the rating (3): c_mean and c_sal. One of the primary research questions was how age related to reaction time, given those differences in pictures. Participants were sampled in age categories: younger (oldage = 0, 40 and under) and older (oldage = 1, above 40). Repeated trials are nested within persons. 10.2.5 Random-Intercept-Only/Null Model Lets estimate our null model with FIML as our estimator and calculate the ICC: null_model &lt;- lmer(lg_rt ~ 1 + (1|id), data = data, REML = FALSE) # note that REML = FALSE performance::icc(null_model) ## # Intraclass Correlation Coefficient ## ## Adjusted ICC: 0.252 ## Conditional ICC: 0.252 With repeated measures data, the ICC is interpreted as the proportion of variance between people: How much of the variance stems from people being different from one another versus fluctuating within themselves? A large ICC means that most of the variability is between people, not from people varying in their answers to a set of questions (or in this case, reaction time). The ICC is 0.252, indicating that 25.2% of the variance in log reaction time is attributed to a person. (Some bonus fun: when responses to questions are nested within person, Cronbachs alpha is equivalent to the ICC: a high alpha indicates high reliability of the scale because most of the scale variance is between people, individuals have relatively consistent patterns of answering on the scale.) 10.2.6 Adding Level-1 Fixed Effects Lets add our level-1 predictors for picture meaning c_mean and picture salience c_sal to our model. This is represented with the following formulae: Level Equation Level 1 \\(lg\\_rt_{ij} = \\beta_{0j} + \\beta_{1j}c\\_mean_{ij} + \\beta_{2j}c\\_sal_{ij} + R_{ij}\\) Level 2 \\(\\beta_{0j} = \\gamma_{00} + U_{0j}\\) \\(\\beta_{1j} = \\gamma_{10}\\) \\(\\beta_{2j} = \\gamma_{20}\\) Combined \\(lg\\_rt_{ij} = \\gamma_{00} + \\gamma_{10}c\\_mean_{ij} + \\gamma_{20}c\\_sal_{ij} + U_{0j} + R_{ij}\\) With this model, were estimating 5 parameters: \\(\\gamma_{00}\\): the fixed effect for the intercept, controlling for c_mean and c_sal; \\(\\gamma_{10}\\): the fixed effect for the slope of c_mean, controlling for c_sal. This represents how meaning affects a persons reaction time  do people respond more quickly or slowly to photos with changes that are related to driving a car (perhaps because theyre often driving and are attuned to changes in the environment when operating a car)? \\(\\gamma_{20}\\): the fixed effect for the slope of c_sal, controlling for c_mean. This represents how salience affects a persons reaction time  do people respond more quickly or slowly to photos with more obvious changes? \\(\\tau_0^2\\): a random effect for the intercept capturing the variance of people around the intercept, controlling for c_mean and c_sal; \\(\\sigma^2\\): a random effect capturing the variance of people around their own mean log reaction time, controlling for c_mean and c_sal. Lets run the model with FIML as our estimator: l1_model &lt;- lmer(lg_rt ~ 1 + c_mean + c_sal + (1|id), data = data, REML = FALSE) summary(l1_model) ## Linear mixed model fit by maximum likelihood . t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: lg_rt ~ 1 + c_mean + c_sal + (1 | id) ## Data: data ## ## AIC BIC logLik deviance df.resid ## 16525.9 16560.6 -8257.9 16515.9 7641 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.5224 -0.7291 -0.1090 0.6177 3.8884 ## ## Random effects: ## Groups Name Variance Std.Dev. ## id (Intercept) 0.1756 0.4191 ## Residual 0.4785 0.6917 ## Number of obs: 7646, groups: id, 153 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 1.605e+00 3.483e-02 1.533e+02 46.09 &lt;2e-16 *** ## c_mean -5.153e-02 4.304e-03 7.493e+03 -11.97 &lt;2e-16 *** ## c_sal -1.323e-01 7.435e-03 7.493e+03 -17.80 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) c_mean ## c_mean 0.044 ## c_sal -0.015 -0.219 The intercept of 1.61 is the mean log reaction time across all people at average values of meaning and salience. A one-unit increase in meaning is associated with a decrease in log reaction time of 0.05 (i.e., a faster reaction time), at the average level of salience. A one-unit increase in salience is associated with a decrease in log reaction time of 0.13 at the average level of meaning. All coefficients are significant. The term describing how people vary around the grand mean intercept is 0.18. The term describing how people vary around their own intercept is 0.48. Does this model have significantly less deviance (i.e., better fit) than the null model alone? Lets use a deviance test to check. Note that we can compare the null and level-1 models because we used FIML as our estimator and they are nested (i.e., all variables in the level-1 model are in the null model). anova(null_model, l1_model) ## Data: data ## Models: ## null_model: lg_rt ~ 1 + (1 | id) ## l1_model: lg_rt ~ 1 + c_mean + c_sal + (1 | id) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## null_model 3 17082 17103 -8537.9 17076 ## l1_model 5 16526 16561 -8257.9 16516 559.94 2 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The level-1 model does have significantly less deviance (16516 compared to 17076 for the null model), so is a better model. Hooray! 10.2.7 Adding Random Slopes Lets try adding random slopes for our level-1 variables of meaning and salience. This allows slopes to vary across people. Maybe some people have stronger relationships between salience and reaction time  such that when the change is more salient they really notice it, and when its less salient they notice it less  while other people have eagle eyes and notice the changes no matter their salience. Level Equation Level 1 \\(lg\\_rt_{ij} = \\beta_{0j} + \\beta_{1j}c\\_mean_{ij} + \\beta_{2j}c\\_sal_{ij} + R_{ij}\\) Level 2 \\(\\beta_{0j} = \\gamma_{00} + U_{0j}\\) \\(\\beta_{1j} = \\gamma_{10} + U_{1j}\\) \\(\\beta_{2j} = \\gamma_{20} + U_{2j}\\) Combined \\(lg\\_rt_{ij} = \\gamma_{00} + \\gamma_{10}c\\_mean_{ij} + \\gamma_{20}c\\_sal_{ij} + U_{0j} + U_{1j}c\\_mean_{ij} + U_{2j}c\\_sal_{ij} + R_{ij}\\) Lets not estimate random effect covariances, so with this model, were estimating 7 parameters: \\(\\gamma_{00}\\): the fixed effect for the intercept, controlling for c_mean and c_sal; \\(\\gamma_{10}\\): the fixed effect for the slope of c_mean, controlling for c_sal; \\(\\gamma_{20}\\): the fixed effect for the slope of c_sal, controlling for c_mean; \\(\\tau_0^2\\): a random effect for the intercept capturing the variance of people around the intercept, controlling for c_mean and c_sal; \\(\\tau_1^2\\): a random effect capturing how peoples slopes for c_mean vary around the grand mean slope, controlling for c_sal; \\(\\tau_2^2\\): a random effect capturing how peoples slopes for c_sal vary around the grand mean slope, controlling for c_mean; \\(\\sigma^2\\): a random effect capturing the variance of people around their own mean log reaction time, controlling for c_mean and c_sal. Lets run our model with random slope effects (but no covariances) in R: l1_random &lt;- lmer(lg_rt ~ 1 + c_mean + c_sal + (1|id) + (0 + c_mean|id) + (0 + c_sal|id), data = data, REML = FALSE) ## boundary (singular) fit: see help(&#39;isSingular&#39;) summary(l1_random) ## Linear mixed model fit by maximum likelihood . t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: lg_rt ~ 1 + c_mean + c_sal + (1 | id) + (0 + c_mean | id) + (0 + c_sal | id) ## Data: data ## ## AIC BIC logLik deviance df.resid ## 16529.4 16578.0 -8257.7 16515.4 7639 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.5320 -0.7287 -0.1087 0.6142 3.8842 ## ## Random effects: ## Groups Name Variance Std.Dev. ## id (Intercept) 1.756e-01 4.191e-01 ## id.1 c_mean 3.766e-09 6.137e-05 ## id.2 c_sal 6.853e-04 2.618e-02 ## Residual 4.777e-01 6.911e-01 ## Number of obs: 7646, groups: id, 153 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 1.605e+00 3.483e-02 1.533e+02 46.09 &lt;2e-16 *** ## c_mean -5.154e-02 4.301e-03 7.337e+03 -11.98 &lt;2e-16 *** ## c_sal -1.323e-01 7.724e-03 1.690e+02 -17.13 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) c_mean ## c_mean 0.044 ## c_sal -0.014 -0.211 ## optimizer (nloptwrap) convergence code: 0 (OK) ## boundary (singular) fit: see help(&#39;isSingular&#39;) We get an estimation error! Recall that singularity occurs when a variance term is close to zero or a correlation between variance terms is near 1 (high multicollinearity). Looking at our output, the variance terms for meaning and salience both look quite small. Lets try to address our estimation issue by removing the smaller of the two, the random effect for c_mean. l1_random_without_cmean &lt;- lmer(lg_rt ~ 1 + c_mean + c_sal + (1|id) + (0 + c_sal|id), data = data, REML = FALSE) summary(l1_random_without_cmean) ## Linear mixed model fit by maximum likelihood . t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: lg_rt ~ 1 + c_mean + c_sal + (1 | id) + (0 + c_sal | id) ## Data: data ## ## AIC BIC logLik deviance df.resid ## 16527.4 16569.0 -8257.7 16515.4 7640 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.5320 -0.7287 -0.1087 0.6142 3.8842 ## ## Random effects: ## Groups Name Variance Std.Dev. ## id (Intercept) 0.1756384 0.41909 ## id.1 c_sal 0.0006842 0.02616 ## Residual 0.4776817 0.69115 ## Number of obs: 7646, groups: id, 153 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 1.605e+00 3.483e-02 1.533e+02 46.09 &lt;2e-16 *** ## c_mean -5.154e-02 4.301e-03 7.352e+03 -11.98 &lt;2e-16 *** ## c_sal -1.323e-01 7.724e-03 1.690e+02 -17.13 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) c_mean ## c_mean 0.044 ## c_sal -0.014 -0.211 That took care of our singularity issue. However, the random effect for salience still looks very small. Lets conduct a deviance test to see if including the random effect reduces deviance at all (that is, whether it is worth it to estimate). anova(l1_random, l1_random_without_cmean) ## Data: data ## Models: ## l1_random_without_cmean: lg_rt ~ 1 + c_mean + c_sal + (1 | id) + (0 + c_sal | id) ## l1_random: lg_rt ~ 1 + c_mean + c_sal + (1 | id) + (0 + c_mean | id) + (0 + c_sal | id) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## l1_random_without_cmean 6 16527 16569 -8257.7 16515 ## l1_random 7 16529 16578 -8257.7 16515 0 1 1 There is no significant difference between these models, so there doesnt seem to be much benefit to including the random effect for salience. 10.2.8 Adding Level-2 Fixed Effects The level-2 variables in our dataset are demographic variables about participants, which in this dataset is their sex, age in years, whether they 40 or older (oldage = 1) or younger than 40 (oldage = 0), or their age centered at 65 years old for those who are older than 40 (yrs65). Lets add oldage and sex as level-2 predictors of the intercept. Level Equation Level 1 \\(lg\\_rt_{ij} = \\beta_{0j} + \\beta_{1j}c\\_mean_{ij} + \\beta_{2j}c\\_sal_{ij} + R_{ij}\\) Level 2 \\(\\beta_{0j} = \\gamma_{00} + \\gamma_{01}oldage_j + \\gamma_{02}sex_j + U_{0j}\\) \\(\\beta_{1j} = \\gamma_{10}\\) \\(\\beta_{2j} = \\gamma_{20}\\) Combined \\(lg\\_rt_{ij} = \\gamma_{00} + \\gamma_{01}oldage_j + \\gamma_{02}sex_j + \\gamma_{10}c\\_mean_{ij} + \\gamma_{20}c\\_sal_{ij} + U_{0j} + R_{ij}\\) Were estimating 7 effects: \\(\\gamma_{00}\\): the fixed effect for the intercept, controlling for c_mean and c_sal; \\(\\gamma_{10}\\): the fixed effect for the slope of c_mean, controlling for c_sal; \\(\\gamma_{20}\\): the fixed effect for the slope of c_sal, controlling for c_mean; \\(\\gamma_{01}\\): the fixed effect for the slope of oldage, controlling for sex, c_mean, and c_sal; \\(\\gamma_{02}\\): the fixed effect for the slope of sex, controlling for oldage, c_mean and c_sal; \\(\\tau_0^2\\): a random effect capturing how peoples mean log reaction times vary around the grand mean log reaction time, controlling for c_mean, c_sal, oldage, and sex; \\(\\sigma^2\\): a random effect capturing the variance of people around their own mean log reaction time, controlling for c_mean, c_sal, oldage, and sex. l2_model &lt;- lmer(lg_rt ~ 1 + c_mean + c_sal + oldage + sex + (1|id), data = data, REML = FALSE) summary(l2_model) ## Linear mixed model fit by maximum likelihood . t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: lg_rt ~ 1 + c_mean + c_sal + oldage + sex + (1 | id) ## Data: data ## ## AIC BIC logLik deviance df.resid ## 16269.8 16318.4 -8127.9 16255.8 7639 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.6108 -0.7341 -0.1058 0.6151 3.9626 ## ## Random effects: ## Groups Name Variance Std.Dev. ## id (Intercept) 0.02424 0.1557 ## Residual 0.47852 0.6918 ## Number of obs: 7646, groups: id, 153 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 1.281e+00 2.566e-02 1.532e+02 49.915 &lt;2e-16 *** ## c_mean -5.150e-02 4.304e-03 7.494e+03 -11.965 &lt;2e-16 *** ## c_sal -1.323e-01 7.434e-03 7.495e+03 -17.801 &lt;2e-16 *** ## oldage 7.994e-01 3.087e-02 1.532e+02 25.891 &lt;2e-16 *** ## sex 4.467e-02 3.045e-02 1.525e+02 1.467 0.144 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) c_mean c_sal oldage ## c_mean 0.059 ## c_sal -0.017 -0.219 ## oldage -0.392 -0.002 -0.003 ## sex -0.681 0.001 -0.002 -0.075 The intercept of 1.28 is the mean log reaction time across all people at average values of meaning and salience for men (sex = 0) who are younger than 40 (oldage = 40). A one-unit increase in meaning is associated with a decrease in log reaction time of 0.05 (i.e., a faster reaction time), controlling for other variables. A one-unit increase in salience is associated with a decrease in log reaction time of 0.13 controlling for other variables. People older than 40 have 0.80 units longer of a log reaction time on average, controlling for other variables. Women have 0.04 unit-slower log reaction times on average, controlling for other variables. All coefficients are significant except for sex. The term describing how people vary around the grand mean intercept is 0.02. The term describing how people vary around their own intercept is 0.48. Lets run a model without the non-significant sex predictor and conduct a deviance test to see if the model fit is negatively impacted. # model l2_model_no_sex &lt;- lmer(lg_rt ~ 1 + c_mean + c_sal + oldage + (1|id), data = data, REML = FALSE) # deviance test anova(l2_model, l2_model_no_sex) ## Data: data ## Models: ## l2_model_no_sex: lg_rt ~ 1 + c_mean + c_sal + oldage + (1 | id) ## l2_model: lg_rt ~ 1 + c_mean + c_sal + oldage + sex + (1 | id) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## l2_model_no_sex 6 16270 16312 -8129.0 16258 ## l2_model 7 16270 16318 -8127.9 16256 2.1363 1 0.1438 There is no significant difference in deviance, so we dont lose on the model fit front if we dont estimate sex. 10.2.9 Adding Cross-Level Interactions For our final model, lets remove the level-2 term for sex and look at a cross-level interaction between oldage and the slope of c_mean to consider the question: does age alter the effect of meaning on reaction times? Level Equation Level 1 \\(lg\\_rt_{ij} = \\beta_{0j} + \\beta_{1j}c\\_mean_{ij} + \\beta_{2j}c\\_sal_{ij} + R_{ij}\\) Level 2 \\(\\beta_{0j} = \\gamma_{00} + \\gamma_{01}oldage_j + U_{0j}\\) \\(\\beta_{1j} = \\gamma_{10} + \\gamma_{11}oldage_j\\) \\(\\beta_{2j} = \\gamma_{20}\\) Combined \\(lg\\_rt_{ij} = \\gamma_{00} + \\gamma_{01}oldage_j + \\gamma_{10}c\\_mean_{ij} + \\gamma_{20}c\\_sal_{ij} + \\gamma_{11}c\\_mean_{ij}*oldage_j + U_{0j} + R_{ij}\\) Were estimating 7 effects: \\(\\gamma_{00}\\): the fixed effect for the intercept, controlling for c_mean, c_sal, and oldage; \\(\\gamma_{10}\\): the fixed effect for the slope of c_mean, controlling for c_sal and oldage; \\(\\gamma_{20}\\): the fixed effect for the slope of c_sal, controlling for c_mean and oldage; \\(\\gamma_{01}\\): the fixed effect for the slope of oldage, controlling for c_mean and c_sal; \\(\\gamma_{11}\\): the fixed effect for the cross-level interaction of oldage with c_mean, controlling for c_sal; \\(\\tau_0^2\\): a random effect capturing how peoples mean log reaction times vary around the grand mean log reaction time, controlling for c_mean, c_sal, and oldage; \\(\\sigma^2\\): a random effect capturing the variance of people around their own mean log reaction time, controlling for c_mean, c_sal, and `oldage``. crosslevel_model &lt;- lmer(lg_rt ~ 1 + c_mean + c_sal + oldage + oldage:c_mean + (1|id), data = data, REML = FALSE) summary(crosslevel_model) ## Linear mixed model fit by maximum likelihood . t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: lg_rt ~ 1 + c_mean + c_sal + oldage + oldage:c_mean + (1 | id) ## Data: data ## ## AIC BIC logLik deviance df.resid ## 16253.8 16302.4 -8119.9 16239.8 7639 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.6032 -0.7333 -0.0988 0.6125 3.9049 ## ## Random effects: ## Groups Name Variance Std.Dev. ## id (Intercept) 0.0247 0.1572 ## Residual 0.4774 0.6909 ## Number of obs: 7646, groups: id, 153 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 1.301e+00 1.895e-02 1.545e+02 68.674 &lt; 2e-16 *** ## c_mean -6.499e-02 5.337e-03 7.493e+03 -12.176 &lt; 2e-16 *** ## c_sal -1.325e-01 7.425e-03 7.495e+03 -17.838 &lt; 2e-16 *** ## oldage 8.154e-01 3.113e-02 1.561e+02 26.194 &lt; 2e-16 *** ## c_mean:oldage 3.717e-02 8.722e-03 7.495e+03 4.261 2.06e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) c_mean c_sal oldage ## c_mean 0.100 ## c_sal -0.025 -0.174 ## oldage -0.608 -0.057 -0.004 ## c_mean:oldg -0.058 -0.593 -0.005 0.095 The interaction between oldage and c_mean is 0.04, suggesting that people older than 40 have 0.04 added to their (log) reaction times for more meaningful photos. That is, older people have slower reaction times even when photos are more related to driving. The other coefficient interpretations are similar to those we discussed in earlier models. 10.3 Conclusion In this chapter, we reviewed our MLM pipeline and applied it to repeated measures without time in the model. In Chapter 10, we will look at longitudinal models, i.e., repeated measures with time in the model. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
